{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWgoG2sR5RkK8OrpGUR6dI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moyen-ahmed/Deep-learning/blob/main/model_desgin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW5yKx48YjSM",
        "outputId": "cb0e4992-198d-44de-b587-55e3627beb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "\n",
        "# ---- core libs ----\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import tqdm, time, copy\n",
        "import heapq\n",
        "import datetime\n",
        "import glob\n",
        "import math, random\n",
        "import pathlib\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "# ---- Keras / TF high-level APIs (use ONLY tensorflow.keras) ----\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.regularizers import *\n",
        "# from tensorflow.keras.layers import Lambda   # use Lambda from tf.keras, not keras\n",
        "\n",
        "# ---- sklearn ----\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---- einops ----\n",
        "import einops\n",
        "from einops import *\n",
        "\n",
        "# ---- random_time replacement (no pip package needed) ----\n",
        "import types as _types\n",
        "import time as _time\n",
        "\n",
        "class RandomTimeModule:\n",
        "    \"\"\"\n",
        "    Simple drop-in replacement so `random_time` exists.\n",
        "    Adjust functions if your later code needs something specific.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def random_delay(min_seconds=0.0, max_seconds=1.0):\n",
        "        return random.uniform(min_seconds, max_seconds)\n",
        "\n",
        "    @staticmethod\n",
        "    def now():\n",
        "        return _time.time()\n",
        "\n",
        "# You can use: random_time.random_delay(...), random_time.now()\n",
        "random_time = RandomTimeModule()\n",
        "\n",
        "# ---- low-level TF ops (only the valid ones) ----\n",
        "from tensorflow import (\n",
        "    abs, cast, clip_by_value, concat, convert_to_tensor,\n",
        "    expand_dims, gather, gather_nd, linspace, map_fn,\n",
        "    norm, pad, repeat, reshape, shape, split,\n",
        "    squeeze, stack, tensor_scatter_nd_update, unstack, zeros,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "\n",
        "import keras\n",
        "from keras import layers, Model   # everything from keras, not tensorflow.keras\n",
        "\n",
        "kr = 2                     # Example hyper-parameter (could be used later, e.g. to scale channels)\n",
        "\n",
        "image_size = 32            # Each input image is 32x32 pixels\n",
        "\n",
        "xput = keras.Input(        # Keras Input layer: defines the shape of one image\n",
        "    shape=(image_size,     #   height  = 32\n",
        "           image_size,     #   width   = 32\n",
        "           3)              #   depth   = 3 (RGB channels)\n",
        ")\n",
        "\n",
        "d1 = xput                  # For now, d1 is just the same tensor as xput\n",
        "                           # In a real model, you would usually do:\n",
        "                           # d1 = layers.Conv2D(...)(xput), etc.\n",
        "\n",
        "\n",
        "# Example: if we add a Conv2D layer, the number of parameters P is:\n",
        "#   P = (N * M * D + 1) * K\n",
        "# where:\n",
        "#   N, M = kernel height and width\n",
        "#   D    = number of input channels (depth)\n",
        "#   K    = number of filters (output channels)\n",
        "#   +1   = one bias term for each filter\n",
        "#\n",
        "# So each filter has N * M * D weights + 1 bias,\n",
        "# and there are K filters in total.\n",
        "\n",
        "# Example Conv2D layer so the formula has context:\n",
        "# N = 3, M = 3, D = 3 (RGB), K = 64\n",
        "# Number of parameters = (3*3*3 + 1) * 64 = (27 + 1) * 64 = 1792\n",
        "# conv = layers.Conv2D(64, (3, 3), padding=\"same\")(d1)\n",
        "\n",
        "\n",
        "class_model = Model(       # Build the Keras Model object\n",
        "    inputs=xput,           # model input tensor\n",
        "    outputs=d1,            # model output tensor\n",
        "    name=\"class_model\"\n",
        ")                          # currently an identity model (output = input)\n",
        "\n",
        "class_model.summary()      # prints layer types, output shapes, and parameter counts\n"
      ],
      "metadata": {
        "id": "fngePzTkloYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now for py tourch\n"
      ],
      "metadata": {
        "id": "PBChIi31mENO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install helper libraries to show model summaries.\n",
        "# torchinfo (newer) and torchsummary (older, similar idea).\n",
        "!pip install torchinfo\n",
        "!pip install torchsummary\n",
        "\n",
        "# Import the neural-network module from PyTorch.\n",
        "# nn contains building blocks like Linear, Conv2d, ReLU, etc.\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import the summary function from torchinfo.\n",
        "# This will print a table of layers, output shapes, and parameter counts.\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 1. Define your model\n",
        "# ===============================\n",
        "\n",
        "# All custom models in PyTorch inherit from nn.Module.\n",
        "class SimpleModel(nn.Module):\n",
        "    # Constructor: here you define and create your layers.\n",
        "    def __init__(self):\n",
        "        # Call the parent class (nn.Module) constructor so that internal\n",
        "        # PyTorch bookkeeping (like parameter registration) is set up correctly.\n",
        "        super(SimpleModel, self).__init__()\n",
        "\n",
        "        # At the moment this model is \"empty\": it has no layers.\n",
        "        # It will simply pass its input directly to the output.\n",
        "        # You could add layers here, for example:\n",
        "        #\n",
        "        # self.conv1 = nn.Conv2d(\n",
        "        #     in_channels=3,    # input has 3 channels (RGB image)\n",
        "        #     out_channels=16,  # produce 16 feature maps\n",
        "        #     kernel_size=3,    # 3x3 convolution kernel\n",
        "        #     padding=1         # keep H,W the same size\n",
        "        # )\n",
        "        #\n",
        "        # self.relu = nn.ReLU()\n",
        "        #\n",
        "        # self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # This method defines how the input tensor flows through the model.\n",
        "    # x is a batch of inputs (e.g. images).\n",
        "    def forward(self, x):\n",
        "        # For this SimpleModel, we do not change x at all.\n",
        "        # In a real model, you would apply layers, for example:\n",
        "        #\n",
        "        # x = self.conv1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.pool(x)\n",
        "        #\n",
        "        # and then return the processed tensor.\n",
        "        #\n",
        "        # Here, we return x directly: this is an identity mapping.\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2. Initialize the model\n",
        "# ===============================\n",
        "\n",
        "# Create an instance of your SimpleModel class.\n",
        "# This allocates all parameters for the layers you defined in __init__.\n",
        "model = SimpleModel()\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. Print model summary\n",
        "# ===============================\n",
        "\n",
        "# Use torchinfo.summary to print a readable summary of the model.\n",
        "# The second argument is the expected input size (excluding batch dimension):\n",
        "#   (3, 32, 32) means:\n",
        "#       3   = number of channels  (e.g., RGB)\n",
        "#       32  = height  in pixels\n",
        "#       32  = width   in pixels\n",
        "#\n",
        "# torchinfo will:\n",
        "#   • simulate a forward pass with a dummy input of shape (1, 3, 32, 32)\n",
        "#   • list each layer\n",
        "#   • show output shape for each layer\n",
        "#   • count trainable and non-trainable parameters\n",
        "summary(model, (3, 32, 32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZE32QJzmHlT",
        "outputId": "72eff053-9f72-4467-be23-7d818d19451e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SimpleModel                              [3, 32, 32]               --\n",
              "==========================================================================================\n",
              "Total params: 0\n",
              "Trainable params: 0\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.01\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model   # Import Keras layers and Model class\n",
        "\n",
        "image_size = 32                              # We will work with 32x32 pixel images\n",
        "\n",
        "# 1) Define the input tensor for the model\n",
        "inputs = layers.Input(                       # Keras Input layer: starting point of the model graph\n",
        "    shape=(image_size,                       #   height  = 32\n",
        "           image_size,                       #   width   = 32\n",
        "           3)                                #   depth   = 3 (RGB channels)\n",
        ")                                            # Shape is (None, 32, 32, 3); None = batch size\n",
        "\n",
        "\n",
        "# 2) First “stage” of the model\n",
        "d1 = inputs                                  # d1 is just another name for the input tensor.\n",
        "                                             # No operation is done yet; it is still (None, 32, 32, 3).\n",
        "\n",
        "\n",
        "# 3) Apply a convolution layer to d1\n",
        "d1 = layers.Conv2D(                          # Create a 2-D convolution layer\n",
        "        10,                                  #   10 filters → output will have 10 channels\n",
        "        kernel_size=(2, 2),                  #   each filter is 2x2 in spatial size\n",
        "        padding='same'                       #   \"same\" padding → output H,W stay 32x32\n",
        "     )(d1)                                   # Immediately apply this layer to tensor d1.\n",
        "                                             # New shape becomes (None, 32, 32, 10).\n",
        "\n",
        "#   Number of parameters in this Conv2D layer:\n",
        "#   Formula: P = (N * M * D + 1) * K\n",
        "#       N, M = kernel height and width = 2, 2\n",
        "#       D    = number of input channels   = 3\n",
        "#       K    = number of filters          = 10\n",
        "#   P = (2 * 2 * 3 + 1) * 10 = (12 + 1) * 10 = 130 parameters\n",
        "\n",
        "\n",
        "# 4) Build the Keras model object\n",
        "class_model = Model(                         # Create a Model that connects input → output\n",
        "    inputs=inputs,                           #   model input tensor (32x32x3 images)\n",
        "    outputs=d1                               #   model output tensor (feature maps 32x32x10)\n",
        ")                                            # This model now consists of one Conv2D layer.\n",
        "\n",
        "\n",
        "# 5) Print a summary of the model architecture\n",
        "class_model.summary()                        # Shows layer types, output shapes, and parameter counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "0qvd7PkDSfyz",
        "outputId": "8a869236-6e0e-436a-b28a-b319b2067031"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We assume torchinfo is already installed:\n",
        "!pip install torchinfo\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 1. Define your model\n",
        "# ===============================\n",
        "\n",
        "class ConvModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network with:\n",
        "    - one Conv2d layer (10 filters, 2x2 kernel, 'same' padding)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Call the parent constructor to set up nn.Module internals\n",
        "        super(ConvModel, self).__init__()\n",
        "\n",
        "        # Define a convolutional layer with 10 filters, 2x2 kernel size, and 'same' padding.\n",
        "        # Arguments:\n",
        "        #   in_channels  = 3   (input image has 3 channels: RGB)\n",
        "        #   out_channels = 10  (number of filters; output will have 10 feature maps)\n",
        "        #   kernel_size  = (2, 2)  (filter height and width)\n",
        "        #   padding      = 'same'  (output spatial size stays the same: 32x32 -> 32x32)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=10,\n",
        "            kernel_size=(2, 2),\n",
        "            padding='same'\n",
        "        )\n",
        "\n",
        "        # Number of parameters in this conv layer:\n",
        "        # Formula: P = (N * M * D + 1) * K\n",
        "        #   N, M = kernel height and width = 2, 2\n",
        "        #   D    = number of input channels   = 3\n",
        "        #   K    = number of filters          = 10\n",
        "        # So:\n",
        "        #   P = (2 * 2 * 3 + 1) * 10 = (12 + 1) * 10 = 130 parameters (weights + biases)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines how the input tensor x flows through the network.\n",
        "\n",
        "        x shape before conv1: (batch_size, 3, 32, 32)\n",
        "        x shape after conv1:  (batch_size, 10, 32, 32)  # padding='same'\n",
        "        \"\"\"\n",
        "        # Apply the convolutional layer to the input tensor x\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # Return the result (feature maps)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2. Initialize the model\n",
        "# ===============================\n",
        "\n",
        "# Create an instance of ConvModel, which allocates conv1 parameters.\n",
        "model = ConvModel()\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. Print model summary\n",
        "# ===============================\n",
        "\n",
        "# Use torchinfo.summary to display the architecture.\n",
        "# input_size is the shape of a single input sample (without batch size):\n",
        "#   (3, 32, 32) = 3 channels, 32x32 pixels.\n",
        "#\n",
        "# torchinfo will internally create a dummy input of shape (1, 3, 32, 32)\n",
        "# and run it through the model to gather shapes and parameter counts.\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(3, 32, 32)   # (channels, height, width)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m84h9Xk1Zh1N",
        "outputId": "73427a56-554b-4be2-8cb4-82872c9e3def"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:543: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /pytorch/aten/src/ATen/native/Convolution.cpp:1031.)\n",
            "  return F.conv2d(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvModel                                [10, 32, 32]              --\n",
              "├─Conv2d: 1-1                            [10, 32, 32]              130\n",
              "==========================================================================================\n",
              "Total params: 130\n",
              "Trainable params: 130\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.04\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.09\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model   # Import Keras layers and Model class\n",
        "\n",
        "image_size = 32                              # We will work with 32x32 pixel images\n",
        "\n",
        "# 1) Define the input tensor for the model\n",
        "inputs = layers.Input(                       # Functional API Input layer: start of the graph\n",
        "    shape=(image_size,                       #   height  = 32\n",
        "           image_size,                       #   width   = 32\n",
        "           3)                                #   channels = 3 (RGB)\n",
        ")                                            # Tensor shape: (None, 32, 32, 3); None = batch size\n",
        "\n",
        "# 2) First “stage” tensor – just an alias of the inputs\n",
        "d1 = inputs                                  # d1 now refers to the same tensor as `inputs`\n",
        "                                            # No operation yet; shape is still (None, 32, 32, 3)\n",
        "\n",
        "\n",
        "# 3) Convolution layer\n",
        "d1 = layers.Conv2D(                          # 2-D convolution over the input image\n",
        "        5,                                   #   out_channels / filters = 5\n",
        "        kernel_size=(3, 3),                  #   filter size = 3x3\n",
        "        padding='same',                      #   keep spatial size: 32x32 -> 32x32\n",
        "        activation='gelu'                    #   apply GELU activation inside this layer\n",
        "     )(d1)                                   # Immediately apply Conv2D to tensor d1\n",
        "                                            # Output shape: (None, 32, 32, 5)\n",
        "\n",
        "#   Parameter count for this Conv2D:\n",
        "#   Formula: P = (N * M * D + 1) * K\n",
        "#       N, M = kernel height, width = 3, 3\n",
        "#       D    = input channels = 3\n",
        "#       K    = number of filters = 5\n",
        "#   So: P = (3 * 3 * 3 + 1) * 5 = (27 + 1) * 5 = 140 trainable parameters\n",
        "\n",
        "\n",
        "# 4) Extra activation layer\n",
        "d1 = layers.Activation('gelu')(d1)          # Apply GELU non-linearity again to the conv output\n",
        "                                            # Note: Conv2D already used activation='gelu',\n",
        "                                            # so this applies GELU twice. In practice you would\n",
        "                                            # usually choose ONE of:\n",
        "                                            #   - activation inside Conv2D, OR\n",
        "                                            #   - a separate Activation layer.\n",
        "\n",
        "\n",
        "# 5) Build the Keras model object\n",
        "class_model = Model(                        # Create a Model that maps inputs → outputs\n",
        "    inputs=inputs,                          #   model input tensor (images)\n",
        "    outputs=d1                              #   final tensor after Conv2D + Activation\n",
        ")                                           # This is a simple 1-layer CNN with GELU\n",
        "\n",
        "# 6) Print the model architecture\n",
        "class_model.summary()                       # Shows layers, output shapes, and parameter counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "K2Ou6rKQcH7Z",
        "outputId": "c9159b2d-3cab-4c29-991c-35a287e048f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │           \u001b[38;5;34m140\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If not installed in this runtime, first run:\n",
        "# !pip install torchinfo -q\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 1. Define the model\n",
        "# ===============================\n",
        "class ConvGELUModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple CNN:\n",
        "      - 1 Conv2d layer with 5 filters (3x3, 'same' padding)\n",
        "      - GELU activation after the convolution\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize the parent nn.Module class\n",
        "        super(ConvGELUModel, self).__init__()\n",
        "\n",
        "        # Define a convolutional layer with 5 filters, 3x3 kernel size, and 'same' padding\n",
        "        # in_channels  = 3    -> input has 3 channels (RGB image)\n",
        "        # out_channels = 5    -> layer produces 5 feature maps\n",
        "        # kernel_size  = (3,3)-> 3x3 convolution kernel\n",
        "        # padding      = 'same' -> keep spatial size (H,W) the same (32x32 -> 32x32)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=5,\n",
        "            kernel_size=(3, 3),\n",
        "            padding='same'\n",
        "        )\n",
        "\n",
        "        # Define the GELU activation function\n",
        "        # This will be applied element-wise to the conv output\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the network.\n",
        "        x: input tensor, shape (batch_size, 3, 32, 32)\n",
        "\n",
        "        After conv1 + GELU:\n",
        "        shape becomes (batch_size, 5, 32, 32)\n",
        "        \"\"\"\n",
        "        # Apply the convolutional layer\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # Apply the GELU activation function\n",
        "        x = self.gelu(x)\n",
        "\n",
        "        # Return the final feature maps\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2. Initialize the model\n",
        "# ===============================\n",
        "model = ConvGELUModel()   # create an instance of the model\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. Print model summary\n",
        "# ===============================\n",
        "# input_size is the size of a single input example (channels, height, width)\n",
        "# Here: 3 channels (RGB), 32x32 pixels\n",
        "summary(model, input_size=(3, 32, 32))   # (channels, height, width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eaQLA0beDSH",
        "outputId": "b95a4218-2229-47e1-8ce1-562944b1135e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvGELUModel                            [5, 32, 32]               --\n",
              "├─Conv2d: 1-1                            [5, 32, 32]               140\n",
              "├─GELU: 1-2                              [5, 32, 32]               --\n",
              "==========================================================================================\n",
              "Total params: 140\n",
              "Trainable params: 140\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.02\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.04\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.05\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model   # Import Keras layers and Model class\n",
        "\n",
        "image_size = 32                              # We will use 32x32 pixel RGB images as input\n",
        "\n",
        "\n",
        "# 1) Define the input tensor for the model\n",
        "inputs = layers.Input(                       # Functional API Input layer: start of the graph\n",
        "    shape=(image_size,                       #   height  = 32\n",
        "           image_size,                       #   width   = 32\n",
        "           3)                                #   channels = 3 (RGB)\n",
        ")                                            # Tensor shape: (None, 32, 32, 3); None = batch size\n",
        "\n",
        "\n",
        "# 2) First alias of the input\n",
        "d1 = inputs                                  # d1 just points to the same tensor as `inputs`\n",
        "                                             # No operation yet; still (None, 32, 32, 3)\n",
        "\n",
        "\n",
        "# 3) Convolution + GELU activation\n",
        "d1 = layers.Conv2D(                          # 2-D convolution layer\n",
        "        filters=1,                           #   number of filters (output channels) = 1\n",
        "        kernel_size=(3, 3),                  #   3x3 convolution kernel\n",
        "        padding='same',                      #   keep H,W the same: 32x32 -> 32x32\n",
        "        activation='gelu'                    #   apply GELU activation inside the layer\n",
        "     )(d1)                                   # Immediately apply this Conv2D to tensor d1\n",
        "                                             # Output shape: (None, 32, 32, 1)\n",
        "\n",
        "#   Parameter count for this Conv2D:\n",
        "#   P = (N * M * D + 1) * K\n",
        "#       N, M = 3, 3 (kernel height, width)\n",
        "#       D    = 3    (input channels)\n",
        "#       K    = 1    (filters)\n",
        "#   P = (3 * 3 * 3 + 1) * 1 = (27 + 1) * 1 = 28 trainable parameters\n",
        "\n",
        "\n",
        "# 4) Batch Normalization\n",
        "d1 = layers.BatchNormalization()(d1)         # Normalize activations over batch:\n",
        "                                             #   y = (x - mean) / sqrt(var + eps) * gamma + beta\n",
        "                                             # Trainable parameters per channel:\n",
        "                                             #   gamma (scale) and beta (shift)\n",
        "                                             # For 1 output channel → 2 trainable params (gamma, beta)\n",
        "                                             # Plus 2 non-trainable (moving mean, moving variance)\n",
        "                                             # Shape remains (None, 32, 32, 1)\n",
        "\n",
        "\n",
        "# 5) Build the Keras model object\n",
        "class_model = Model(                         # Create a Model mapping inputs → outputs\n",
        "    inputs=inputs,                           #   model input tensor\n",
        "    outputs=d1                               #   final tensor after Conv2D + BatchNorm\n",
        ")                                            # This is a small CNN block: Conv + GELU + BN\n",
        "\n",
        "\n",
        "# 6) Show the model architecture\n",
        "class_model.summary()                        # Prints layers, output shapes, and parameter counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "mOXk3e6fhn7M",
        "outputId": "ab5447af-d47b-4f07-f3f7-e1658f9c9b94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m28\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m4\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "class ConvGELUBNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Conv + GELU + BatchNorm2d block.\n",
        "\n",
        "    Input : (batch_size, 3, 32, 32)    # 3-channel 32x32 image (e.g. RGB)\n",
        "    Output: (batch_size, 1, 32, 32)    # 1 feature map after conv+GELU+BN\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvGELUBNModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=1,\n",
        "            kernel_size=(3, 3),\n",
        "            padding=1          # padding=1 ≈ 'same' for 3x3\n",
        "        )\n",
        "\n",
        "        self.gelu = nn.GELU()\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)       # (B, 3, 32, 32) -> (B, 1, 32, 32)\n",
        "        x = self.gelu(x)        # non-linear activation\n",
        "        x = self.batch_norm(x)  # normalize over batch & spatial dims\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvGELUBNModel()\n",
        "\n",
        "# IMPORTANT: include batch dimension N in input_size\n",
        "summary(model, input_size=(1, 3, 32, 32))   # (batch, channels, height, width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a65slz4kH3o",
        "outputId": "49aed3f9-4650-4d3f-cddf-048e9ed29739"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvGELUBNModel                          [1, 1, 32, 32]            --\n",
              "├─Conv2d: 1-1                            [1, 1, 32, 32]            28\n",
              "├─GELU: 1-2                              [1, 1, 32, 32]            --\n",
              "├─BatchNorm2d: 1-3                       [1, 1, 32, 32]            2\n",
              "==========================================================================================\n",
              "Total params: 30\n",
              "Trainable params: 30\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.03\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.02\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.03\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "image_size = 32                              # Input images are 32×32 pixels\n",
        "\n",
        "# ----- Input -----\n",
        "inputs = layers.Input(                       # Functional API Input layer\n",
        "    shape=(image_size, image_size, 3)        # (H, W, C) = (32, 32, 3) for RGB\n",
        ")\n",
        "\n",
        "d1 = inputs                                  # Start the block using the input tensor\n",
        "\n",
        "\n",
        "# ----- Conv2D + GELU -----\n",
        "d1 = layers.Conv2D(\n",
        "        filters=5,                           # 5 output channels (feature maps)\n",
        "        kernel_size=(3, 3),                  # 3×3 convolution kernel\n",
        "        padding='same',                      # keep H,W = 32×32\n",
        "        activation='gelu'                    # apply GELU inside this layer\n",
        "    )(d1)                                    # apply conv to tensor d1\n",
        "# Shape now: (None, 32, 32, 5)\n",
        "\n",
        "\n",
        "# ----- Batch Normalization -----\n",
        "d1 = layers.BatchNormalization()(d1)         # normalize each channel over the batch\n",
        "# Shape remains: (None, 32, 32, 5)\n",
        "\n",
        "\n",
        "# ----- MaxPooling -----\n",
        "d1 = layers.MaxPool2D()(d1)                  # default pool_size=(2,2), stride=2\n",
        "# Now H,W are halved: shape → (None, 16, 16, 5)\n",
        "\n",
        "\n",
        "# ----- Build the model -----\n",
        "class_model = Model(inputs=inputs, outputs=d1)\n",
        "class_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "tzVRyfOQph_l",
        "outputId": "08f8979e-0d94-4edd-e1fa-03667f2749b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │           \u001b[38;5;34m140\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │            \u001b[38;5;34m20\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m150\u001b[0m (600.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> (600.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If torchinfo is not installed in this runtime, run once:\n",
        "!pip install torchinfo -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "class ConvGELUBNMaxPoolModel(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch version of:\n",
        "        Conv2D(5, 3x3, padding='same', activation='gelu')\n",
        "        -> BatchNormalization\n",
        "        -> MaxPool2D\n",
        "    Input : (batch_size, 3, 32, 32)\n",
        "    Output: (batch_size, 5, 16, 16)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize parent nn.Module\n",
        "        super(ConvGELUBNMaxPoolModel, self).__init__()\n",
        "\n",
        "        # 1) Convolution layer\n",
        "        #    Keras: Conv2D(5, kernel_size=(3,3), padding='same', activation='gelu')\n",
        "        #\n",
        "        # in_channels  = 3   → RGB image (3 channels)\n",
        "        # out_channels = 5   → 5 filters → 5 output feature maps\n",
        "        # kernel_size  = 3   → 3x3 kernel\n",
        "        # padding      = 1   → for 3x3 kernel, padding=1 gives \"same\" spatial size:\n",
        "        #                       input 32x32 → output 32x32\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=5,\n",
        "            kernel_size=3,\n",
        "            padding=1\n",
        "        )\n",
        "\n",
        "        # 2) GELU activation\n",
        "        #    Keras: activation='gelu'\n",
        "        # Applies Gaussian Error Linear Unit element-wise.\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "        # 3) Batch Normalization\n",
        "        #    Keras: BatchNormalization()\n",
        "        #\n",
        "        # BatchNorm2d normalizes across (N, H, W) for each channel.\n",
        "        # num_features = number of channels coming from conv layer = 5\n",
        "        self.bn = nn.BatchNorm2d(num_features=5)\n",
        "\n",
        "        # 4) Max pooling\n",
        "        #    Keras: MaxPool2D()  (default pool_size=(2,2), strides=2)\n",
        "        #\n",
        "        # kernel_size = 2, stride = 2 → halves height and width:\n",
        "        #   32x32 → 16x16\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the network.\n",
        "\n",
        "        Input shape : (batch_size, 3, 32, 32)\n",
        "        After conv   : (batch_size, 5, 32, 32)\n",
        "        After GELU   : (batch_size, 5, 32, 32)\n",
        "        After BN     : (batch_size, 5, 32, 32)\n",
        "        After pool   : (batch_size, 5, 16, 16)\n",
        "        \"\"\"\n",
        "        x = self.conv(x)   # Conv2d\n",
        "        x = self.gelu(x)   # GELU activation\n",
        "        x = self.bn(x)     # BatchNorm2d\n",
        "        x = self.pool(x)   # MaxPool2d\n",
        "        return x\n",
        "\n",
        "\n",
        "# ----- create model instance -----\n",
        "model = ConvGELUBNMaxPoolModel()\n",
        "\n",
        "# ----- show summary (like model.summary() in Keras) -----\n",
        "# torchinfo expects FULL 4D input size: (batch, channels, height, width)\n",
        "summary(model, input_size=(1, 3, 32, 32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_8QBq-PqaSp",
        "outputId": "801444fe-0bae-4d74-fddb-aa73fc0db733"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvGELUBNMaxPoolModel                   [1, 5, 16, 16]            --\n",
              "├─Conv2d: 1-1                            [1, 5, 32, 32]            140\n",
              "├─GELU: 1-2                              [1, 5, 32, 32]            --\n",
              "├─BatchNorm2d: 1-3                       [1, 5, 32, 32]            10\n",
              "├─MaxPool2d: 1-4                         [1, 5, 16, 16]            --\n",
              "==========================================================================================\n",
              "Total params: 150\n",
              "Trainable params: 150\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.14\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.09\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}